{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOFRt5kyifRV69zLePRaqHn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# DSBA 6165 Milestone One Prompt Testing"],"metadata":{"id":"PkFpL8R7q5ij"}},{"cell_type":"markdown","source":["## Software Set up"],"metadata":{"id":"k6n72BmlrEA1"}},{"cell_type":"markdown","source":["### Install Modules"],"metadata":{"id":"hCClzgT3rHsP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQAZxHN4DGcz"},"outputs":[],"source":["!pip install openai\n","!pip install langfuse"]},{"cell_type":"markdown","source":["### Import Modules"],"metadata":{"id":"gfkfqWcarOLu"}},{"cell_type":"code","source":["# Gemini\n","import google.generativeai as genai\n","from openai import OpenAI\n","from google.colab import userdata\n","\n","# Core Python Libraries\n","import json\n","import os\n","import sys\n","import requests\n","\n","from datetime import date\n","from scipy.optimize import minimize\n","\n","# Data Science Specific Libraries\n","import pandas as pd\n","import numpy as np\n","\n","# Google Collab Goodies\n","from IPython.display import display_markdown, display_html\n","from google.colab import data_table\n","data_table.enable_dataframe_formatter()\n","from google.colab import drive\n","\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as go\n","\n","from PIL import Image\n","import pytest\n","\n","from langfuse import Langfuse\n","from langfuse.decorators import observe\n","from langfuse.openai import openai # OpenAI integration\n"],"metadata":{"id":"1bBL_hXJrYXp","executionInfo":{"status":"ok","timestamp":1726147598163,"user_tz":240,"elapsed":7661,"user":{"displayName":"Rich Mcknight","userId":"05510168484912007771"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Constants"],"metadata":{"id":"jgR2C2RKt7xJ"}},{"cell_type":"code","source":["CLIENT = OpenAI(api_key=userdata.get(\"DSBA_LLAMA3_KEY\"))\n","CLIENT.base_url = userdata.get(\"MODAL_BASE_URL\")\n","MODEL = \"/models/NousResearch/Meta-Llama-3-8B-Instruct\"\n","\n","\n","langfuse = Langfuse(\n","  secret_key=userdata.get(\"lang-fuse-api\"),\n","  public_key=\"pk-lf-7123ad96-768d-4e17-98e7-acbcd0058798\",\n","  host=\"https://us.cloud.langfuse.com\"\n",")"],"metadata":{"id":"eirShAuTt_0o","executionInfo":{"status":"ok","timestamp":1726147599731,"user_tz":240,"elapsed":1578,"user":{"displayName":"Rich Mcknight","userId":"05510168484912007771"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Reusable Code"],"metadata":{"id":"rtsK3lTJrpSn"}},{"cell_type":"code","source":["@observe()\n","def submit_prompt(\n","    messages,\n","    stream=True,\n","    temperature=0.7,             # Controls creativity (0 to 2, higher means more creative)\n","    max_tokens=128,              # Limits the response length\n","    top_p=0.9,                   # Controls diversity via nucleus sampling (0 to 1)\n","    #top_k=50,                    # Limits token sampling (0 disables this, higher gives more variety)\n","    presence_penalty=0.6,        # Discourages repeating tokens (ranges from -2 to 2)\n","    frequency_penalty=0.4,       # Penalty based on how often tokens appear in the response (ranges from -2 to 2)\n","    stop=[\"\\n\"]                  # Stop sequences to control when the model stops generating\n","):\n","    stream = CLIENT.chat.completions.create(\n","        model=MODEL,\n","        messages=messages,\n","        stream=stream,\n","        temperature=temperature,\n","        max_tokens=max_tokens,\n","        top_p=top_p,\n","       # top_k=top_k,\n","        presence_penalty=presence_penalty,\n","        frequency_penalty=frequency_penalty,\n","        stop=stop\n","    )\n","    response=\"\"\n","    for chunk in stream:\n","      if chunk.choices[0].delta.content is not None:\n","          response += chunk.choices[0].delta.content\n","    return response\n","\n","\n","def get_clarification(message):\n","  messages = [\n","    {\n","        \"role\": \"system\",\n","        \"content\": \"You are a copy editor, please clarify the text that I provide with two versions, one that maximizes clarity and one that preserves my voice.\",\n","    },\n","    {\n","        \"role\": \"user\",\n","        \"content\": message,\n","    },\n","  ]\n","\n","  response = submit_prompt(messages)\n","  return response\n","\n","def translate(message, to_lang, from_lang=\"en_US\",temperature=0.7,max_tokens=250,top_p=1):\n","  messages = [\n","    {\n","        \"role\": \"system\",\n","        \"content\": f\"translate the message provided from {from_lang} to {to_lang}. Please do not add any quotes, or trailing or leading spaces\",\n","    },\n","    {\n","        \"role\": \"user\",\n","        \"content\": message,\n","    },\n","  ]\n","\n","  response = submit_prompt(messages,temperature=temperature,top_p=top_p,max_tokens=max_tokens)\n","  return response\n"],"metadata":{"id":"NVtkK7W5ro8G","executionInfo":{"status":"ok","timestamp":1726147599731,"user_tz":240,"elapsed":3,"user":{"displayName":"Rich Mcknight","userId":"05510168484912007771"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Tests"],"metadata":{"id":"TMjrjBFOwIU0"}},{"cell_type":"markdown","source":["### Translations"],"metadata":{"id":"zCzN8AfywMYC"}},{"cell_type":"code","source":["response = translate('''\n","hood\n","''',to_lang=\"en_GB\",temperature=1.5,top_p=.5,max_tokens=200)\n","display_markdown(response,raw=True)"],"metadata":{"id":"Pbkw3OdKwK8u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Pytests"],"metadata":{"id":"S909tSxyFJhU"}},{"cell_type":"code","source":["def same_string(response,expected):\n","    assert response.strip() == expected.strip(), f\"Expected {expected.strip()}, but got {response.strip()}\"\n","\n","def test_to_brit_1():\n","    expected = 'Open the boot'\n","    \"\"\"Test Translation from US to GB English.\"\"\"\n","    message=\"Open the trunk\"\n","    response=translate(message,\n","      to_lang=\"en_GB\",temperature=.07,top_p=.2,max_tokens=20)\n","    same_string(response,expected)\n","\n","def test_to_brit_1a():\n","    expected = 'Open the boot'\n","    \"\"\"Test Translation from US to GB English in Drunk Mode.\"\"\"\n","    message=\"Open the trunk\"\n","    response=translate(message,\n","      to_lang=\"en_GB\",temperature=2.0,top_p=.8,max_tokens=20)\n","    same_string(response,expected)\n","\n","def test_to_brit_2():\n","    expected = 'Open the bonnet'\n","    \"\"\"Test Translation from US to GB English.\"\"\"\n","    message=\"Open the hood\"\n","    response=translate(message,\n","      to_lang=\"en_GB\",temperature=.07,top_p=.2,max_tokens=20)\n","    same_string(response,expected)\n","\n","def test_to_brit_3():\n","    expected =\"Ride the lift\"\n","    message=\"Ride the elevator\"\n","    response=translate(message,\n","      to_lang=\"en_GB\",temperature=.07,top_p=.2,max_tokens=20)\n","    same_string(response,expected)\n","\n","def run_tests(test_functions):\n","    for test in test_functions:\n","        try:\n","            test()\n","            print(f\"{test.__name__} Passed\")\n","        except AssertionError as e:\n","            print(f\"{test.__name__} Failed: {e}\")\n","\n","if False:\n","  test_to_brit_1()\n","  print(\"Test 1 Passed\")\n","  test_to_brit_2()\n","  print(\"Test 2 Passed\")\n","  test_to_brit_3()\n","  print(\"Test 3 Passed\")\n","  test_to_brit_1a() # Drunk Mode will always fail\n","  print(\"Test 1a Passed\")"],"metadata":{"id":"yGuPfQKPFId2","executionInfo":{"status":"aborted","timestamp":1726147601743,"user_tz":240,"elapsed":1,"user":{"displayName":"Rich Mcknight","userId":"05510168484912007771"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Run Tests"],"metadata":{"id":"DxWo6OvdYXvG"}},{"cell_type":"code","source":["# Automatically find all functions starting with 'test_'\n","test_functions = [func for name, func in globals().items() if callable(func) and name.startswith(\"test_\")]\n","\n","# Run the tests\n","run_tests(test_functions)"],"metadata":{"id":"2TvQgZ0vYVVa","executionInfo":{"status":"aborted","timestamp":1726147601743,"user_tz":240,"elapsed":1,"user":{"displayName":"Rich Mcknight","userId":"05510168484912007771"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Appendix"],"metadata":{"id":"vH4opOGVYxFb"}},{"cell_type":"markdown","source":["## Getting By With a Little Help from an LLM\n","\n","**Link**: `https://chatgpt.com/share/ab631e53-78f4-4055-8eb5-311fc5e928c1`\n","\n","### Prompt\n","\n","I have this code ....\n","\n","```\n","def same_string(response,expected):\n","    assert response.strip() == expected.strip(), f\"Expected {expected.strip()}, but got {response.strip()}\"\n","\n","def test_to_brit_1():\n","    expected = 'Open the boot'\n","    \"\"\"Test Translation from US to GB English.\"\"\"\n","    message=\"Open the trunk\"\n","    response=translate(message,\n","      to_lang=\"en_GB\",temperature=.07,top_p=.2,max_tokens=20)\n","    same_string(response,expected)\n","\n","def test_to_brit_1a():\n","    expected = 'Open the boot'\n","    \"\"\"Test Translation from US to GB English in Drunk Mode.\"\"\"\n","    message=\"Open the trunk\"\n","    response=translate(message,\n","      to_lang=\"en_GB\",temperature=2.0,top_p=.8,max_tokens=20)\n","    same_string(response,expected)\n","\n","def test_to_brit_2():\n","    expected = 'Open the bonnet'\n","    \"\"\"Test Translation from US to GB English.\"\"\"\n","    message=\"Open the hood\"\n","    response=translate(message,\n","      to_lang=\"en_GB\",temperature=.07,top_p=.2,max_tokens=20)\n","    same_string(response,expected)\n","\n","def test_to_brit_3():\n","    expected =\"Ride the lift\"\n","    message=\"Ride the elevator\"\n","    response=translate(message,\n","      to_lang=\"en_GB\",temperature=.07,top_p=.2,max_tokens=20)\n","    same_string(response,expected)\n","\n","test_to_brit_1()\n","print(\"Test 1 Passed\")\n","test_to_brit_2()\n","print(\"Test 2 Passed\")\n","test_to_brit_3()\n","print(\"Test 3 Passed\")\n","test_to_brit_1a() # Drunk Mode will always fail\n","print(\"Test 1a Passed\")\n","```\n","\n","I dont think that I can use pytest.main() inside of google collab  --\n","is there any way for me to iterate through the tests (i would be happy to manually create the list of functions if necessary) also is there a way to run it that catches the assertion error prints a message and continues through the list.\n","\n","Alternatively if there is a way to query google colab for all of the functions that were defined by name (I am happy populate the list of functions by matching a pattern)\n","\n","### Response\n","\n","In Google Colab, you can manually iterate through a list of test functions, catch assertion errors, and continue running the remaining tests. Here’s an example that wraps your tests in a try-except block to handle assertion errors:\n","\n","```python\n","def run_tests(test_functions):\n","    for test in test_functions:\n","        try:\n","            test()\n","            print(f\"{test.__name__} Passed\")\n","        except AssertionError as e:\n","            print(f\"{test.__name__} Failed: {e}\")\n","\n","# Manually create a list of test functions\n","test_functions = [test_to_brit_1, test_to_brit_2, test_to_brit_3, test_to_brit_1a]\n","\n","# Run the tests\n","run_tests(test_functions)\n","```\n","\n","This approach manually defines a list of functions and uses a `try-except` block to catch any `AssertionError`, print the error message, and continue with the next test.\n","\n","Alternatively, if you want to automatically find all test functions matching a specific pattern (e.g., functions that start with `test_`), you can use Python’s `globals()` to inspect the defined functions:\n","\n","```python\n","# Automatically find all functions starting with 'test_'\n","test_functions = [func for name, func in globals().items() if callable(func) and name.startswith(\"test_\")]\n","\n","# Run the tests\n","run_tests(test_functions)\n","```\n","\n","This way, you can avoid manually listing the functions."],"metadata":{"id":"wF2MRC3GW4AC"}},{"cell_type":"markdown","source":["## Debug Code"],"metadata":{"id":"Ap4x6kpxWui2"}},{"cell_type":"code","source":["def test_string(response,expected):\n","    \"\"\"Unit Test Pytest logic\"\"\"\n","    assert response.strip() == expected.strip(), f\"Expected {expected.strip()}, but got {response.strip()}\"\n","\n","test_string(\" A\",\"A \")"],"metadata":{"id":"UONRo7iQIoIn","executionInfo":{"status":"ok","timestamp":1726109780929,"user_tz":240,"elapsed":181,"user":{"displayName":"Rich Mcknight","userId":"05510168484912007771"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["print((\" E \".strip()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Vk0xMQFJsfp","executionInfo":{"status":"ok","timestamp":1726109716199,"user_tz":240,"elapsed":193,"user":{"displayName":"Rich Mcknight","userId":"05510168484912007771"}},"outputId":"2d85cb2a-7602-4255-9115-8da244da5590"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["E\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"SkaSSDxqWy3K"},"execution_count":null,"outputs":[]}]}